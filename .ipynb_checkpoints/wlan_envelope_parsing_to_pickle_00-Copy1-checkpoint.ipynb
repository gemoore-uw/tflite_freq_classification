{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T22:17:53.490768Z",
     "start_time": "2019-10-23T22:17:53.487701Z"
    }
   },
   "source": [
    "# wlan_envelope_parsing_to_pickle_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # !!! \"=-1\" Forces system to not use GPU (This can allow for simultaneous training via GPU and testing via CPU)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from tensorflow.contrib import rnn, layers\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import channels\n",
    "\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "from time import sleep\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import pixiedust # Visual Debugger\n",
    "\n",
    "import data_utils_wlan_v2 as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/mnt/2ndSSD/802-11_datasets/wlan_enveloped'\n",
    "data_path = folder_path + '/data'\n",
    "project_name = 'nn_classification'\n",
    "version = '_v16'\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = folder_path + \"/logs_\" + project_name + version\n",
    "if not os.path.exists(root_logdir):\n",
    "    os.mkdir(root_logdir)\n",
    "\n",
    "# Tensorboard folders\n",
    "logs_dir = \"{}/run-{}\".format(root_logdir,now)\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.mkdir(logs_dir)\n",
    "\n",
    "if not os.path.exists(logs_dir + '/train'):\n",
    "    os.mkdir(logs_dir + '/train')\n",
    "    \n",
    "if not os.path.exists(logs_dir + '/valid'):\n",
    "    os.mkdir(logs_dir + '/valid')\n",
    "\n",
    "# Checkpoints folder\n",
    "checkpoints_dir = folder_path + \"/checkpoints_\" + project_name + version\n",
    "if not os.path.exists(checkpoints_dir):\n",
    "    os.mkdir(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *.mat to *.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "n_data_packets_in_mat = 12000\n",
    "n_data_packet_type = 3\n",
    "n_ctrl_packet_types = 6\n",
    "\n",
    "n_snr = 1\n",
    "sample_types = 2 #iq data\n",
    "           \n",
    "rf_signal_list = []\n",
    "pickle = True\n",
    "for filename in sorted(listdir(data_path)):\n",
    "    filepath = join(data_path, filename)\n",
    "    if fnmatch(filepath, '*.mat'):        \n",
    "        print(\"\\n\" + filename)\n",
    "        protocol = filename.split('_')[3][-1]\n",
    "        mcs = filename.split('_')[8][-1]\n",
    "        print(\"802.11 Protocol: \" + protocol + \"| MCS: \" + mcs)\n",
    "        rf_signal_list.append(protocol + mcs)\n",
    "       \n",
    "        data_packets_r, data_packets_i, ctrl_packets_r, ctrl_packets_i = data_utils.loadMatData(filepath, n_data_packets_in_mat, n_ctrl_packet_types)\n",
    "        \n",
    "        n_samples_per_packet_type = int(n_data_packets_in_mat/3);\n",
    "        data_packets = data_utils.process_data(n_data_packets_in_mat, n_samples_per_packet_type, n_data_packet_type, n_snr, \\\n",
    "                            np.size(ctrl_packets_r, 0), sample_types, data_packets_r, data_packets_i)\n",
    "        print(\"Data Shape: {}\".format(np.shape(data_packets)))\n",
    "        \n",
    "        n_samples_per_packet_type = 1\n",
    "        ctrl_packets = data_utils.process_data(n_ctrl_packet_types, n_samples_per_packet_type, n_ctrl_packet_types, n_snr, \\\n",
    "                            np.size(ctrl_packets_r, 0), sample_types, ctrl_packets_r, ctrl_packets_i)\n",
    "        print(\"Ctrl Shape: {}\".format(np.shape(ctrl_packets)))\n",
    "        \n",
    "        if pickle is True:\n",
    "            pickle_data_filename = '/' + filename.split('.')[0]+'_data.p'\n",
    "            pickle_ctrl_filename = '/' + filename.split('.')[0]+'_ctrl.p'\n",
    "            data_utils.pickle_tensor(data_packets, data_path + pickle_data_filename)\n",
    "            data_utils.pickle_tensor(ctrl_packets, data_path + pickle_ctrl_filename)\n",
    "        \n",
    "print(\"\\nProtocols: {}\".format(rf_signal_list))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "TF_K_SKL_P_GPU_191124",
   "language": "python",
   "name": "tf_k_skl_p_gpu_191124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
